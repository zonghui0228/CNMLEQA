{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b854a20-a00f-48b9-82bb-9b0f5836c6c0",
   "metadata": {},
   "source": [
    "## è½½å…¥ä¾èµ–åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175502f4-97a3-4195-bb7d-ad755ab0412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from ollama import chat\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import create_engine, Column, Text, String, Integer, MetaData, Table, select\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501f5e0-1833-4ba0-917f-468378d76b60",
   "metadata": {},
   "source": [
    "## è¯»å–æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21df89e8-6ad4-48f4-8097-5fa54e39c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10694, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>opa</th>\n",
       "      <th>opb</th>\n",
       "      <th>opc</th>\n",
       "      <th>opd</th>\n",
       "      <th>ope</th>\n",
       "      <th>answer</th>\n",
       "      <th>year</th>\n",
       "      <th>question_number</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å°å‰‚é‡åœ°å¡ç±³æ¾æŠ‘åˆ¶è¯•éªŒé€‚ç”¨äºï¼ˆ ï¼‰ã€‚</td>\n",
       "      <td>é†›å›ºé…®å¢å¤šç—‡å®šæ€§</td>\n",
       "      <td>è‚¾ä¸Šè…ºçš®è´¨å¢å¤šç—‡å®šæ€§</td>\n",
       "      <td>è‚¾ä¸Šè…ºçš®è´¨åŠŸèƒ½å‡é€€ç—‡å®šä½</td>\n",
       "      <td>è‚¾ä¸Šè…ºçš®è´¨åŠŸèƒ½å‡é€€ç—‡å®šæ€§</td>\n",
       "      <td>è‚¾ä¸Šè…ºçš®è´¨å¢å¤šç—‡å®šä½</td>\n",
       "      <td>opb</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pubmed-38355517;github-llm-chinese-nmle</td>\n",
       "      <td>413f38dc-3df2-5955-8858-16e460462f44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ä¸‹åˆ—æˆåˆ†å¯è§äºè‚¾å°ç®¡æ€§è›‹ç™½å°¿çš„æ˜¯ï¼ˆ ï¼‰ã€‚</td>\n",
       "      <td>IgM</td>\n",
       "      <td>è¡¥ä½“</td>\n",
       "      <td>IgG</td>\n",
       "      <td>Î²2å¾®çƒè›‹ç™½</td>\n",
       "      <td>æœ¬å‘¨è›‹ç™½</td>\n",
       "      <td>opd</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pubmed-38355517;github-llm-chinese-nmle</td>\n",
       "      <td>45ba857a-8989-5527-89cc-d4320f8b3226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>åŸå‘æ€§è‚¾å°çƒç–¾ç—…çš„ä¸´åºŠåˆ†ç±»ä¸åŒ…æ‹¬ï¼ˆ ï¼‰ã€‚</td>\n",
       "      <td>æ— ç—‡çŠ¶æ€§è¡€å°¿æˆ–ï¼ˆå’Œï¼‰è›‹ç™½å°¿</td>\n",
       "      <td>æ…¢æ€§è‚¾å°çƒè‚¾ç‚</td>\n",
       "      <td>è‚¾ç—…ç»¼åˆå¾</td>\n",
       "      <td>æ€¥è¿›æ€§è‚¾å°çƒè‚¾ç‚</td>\n",
       "      <td>è‚¾ç›‚è‚¾ç‚</td>\n",
       "      <td>ope</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pubmed-38355517;github-llm-chinese-nmle</td>\n",
       "      <td>a0a85ae8-48a3-5371-8e71-a60c600c0269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               question            opa         opb           opc  \\\n",
       "0    å°å‰‚é‡åœ°å¡ç±³æ¾æŠ‘åˆ¶è¯•éªŒé€‚ç”¨äºï¼ˆ ï¼‰ã€‚       é†›å›ºé…®å¢å¤šç—‡å®šæ€§  è‚¾ä¸Šè…ºçš®è´¨å¢å¤šç—‡å®šæ€§  è‚¾ä¸Šè…ºçš®è´¨åŠŸèƒ½å‡é€€ç—‡å®šä½   \n",
       "1  ä¸‹åˆ—æˆåˆ†å¯è§äºè‚¾å°ç®¡æ€§è›‹ç™½å°¿çš„æ˜¯ï¼ˆ ï¼‰ã€‚            IgM          è¡¥ä½“           IgG   \n",
       "2  åŸå‘æ€§è‚¾å°çƒç–¾ç—…çš„ä¸´åºŠåˆ†ç±»ä¸åŒ…æ‹¬ï¼ˆ ï¼‰ã€‚  æ— ç—‡çŠ¶æ€§è¡€å°¿æˆ–ï¼ˆå’Œï¼‰è›‹ç™½å°¿     æ…¢æ€§è‚¾å°çƒè‚¾ç‚         è‚¾ç—…ç»¼åˆå¾   \n",
       "\n",
       "            opd         ope answer    year  question_number  \\\n",
       "0  è‚¾ä¸Šè…ºçš®è´¨åŠŸèƒ½å‡é€€ç—‡å®šæ€§  è‚¾ä¸Šè…ºçš®è´¨å¢å¤šç—‡å®šä½    opb  2017.0              1.0   \n",
       "1        Î²2å¾®çƒè›‹ç™½        æœ¬å‘¨è›‹ç™½    opd  2017.0              2.0   \n",
       "2      æ€¥è¿›æ€§è‚¾å°çƒè‚¾ç‚        è‚¾ç›‚è‚¾ç‚    ope  2017.0              3.0   \n",
       "\n",
       "                                    source  \\\n",
       "0  pubmed-38355517;github-llm-chinese-nmle   \n",
       "1  pubmed-38355517;github-llm-chinese-nmle   \n",
       "2  pubmed-38355517;github-llm-chinese-nmle   \n",
       "\n",
       "                                     id  \n",
       "0  413f38dc-3df2-5955-8858-16e460462f44  \n",
       "1  45ba857a-8989-5527-89cc-d4320f8b3226  \n",
       "2  a0a85ae8-48a3-5371-8e71-a60c600c0269  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¯»å–JSONæ–‡ä»¶å¹¶åˆ›å»ºDataFrame\n",
    "df = pd.read_json('CMedExamQA.json')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57999e28-28b0-4a6d-b5d8-1060e44040e1",
   "metadata": {},
   "source": [
    "## è°ƒç”¨å¤§æ¨¡å‹ï¼Œè·å¾—responseï¼Œå¹¶å­˜å‚¨åœ¨SQLiteæ•°æ®åº“é‡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7711cdd9-40eb-46c3-ac53-c653385f7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_api_key = \"sk-****\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b672331d-5728-4a14-a4dc-91e706d241a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "def call_openai(model, content):\n",
    "    client = OpenAI(api_key=gpt_api_key)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": content}\n",
    "      ]\n",
    "    )\n",
    "    response_text = completion.choices[0].message.content\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e6b60-7338-4e3b-bed0-718d731601f1",
   "metadata": {},
   "source": [
    "### è°ƒç”¨ä¸€ä¸ªæ ·ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31e42a2-5886-4a03-abbd-303cbc0430d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"answer\": \"B\"}\n"
     ]
    }
   ],
   "source": [
    "model=\"gpt-4o\"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    qid = row[\"id\"]\n",
    "    question = row[\"question\"]\n",
    "    opa = row[\"opa\"]\n",
    "    opb = row[\"opb\"]\n",
    "    opc = row[\"opc\"]\n",
    "    opd = row[\"opd\"]\n",
    "    ope = row[\"ope\"]\n",
    "    if qid == \"413f38dc-3df2-5955-8858-16e460462f44\":\n",
    "        prompt = f\"\"\"è¯·æ ¹æ®ä»¥ä¸‹åŒ»å­¦å•é€‰é¢˜ï¼Œä»äº”ä¸ªé€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åˆé€‚çš„ç­”æ¡ˆï¼Œå¹¶å°†ç­”æ¡ˆä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "        {{\"answer\": \"X\"}}\n",
    "        \n",
    "        å…¶ä¸­ X æ˜¯ Aã€Bã€Cã€D æˆ– E ä¸­çš„ä¸€ä¸ªé€‰é¡¹ã€‚è¯·ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–é¢å¤–ä¿¡æ¯ã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {question}\n",
    "        A. {opa}\n",
    "        B. {opb}\n",
    "        C. {opc}\n",
    "        D. {opd}\n",
    "        E. {ope}\n",
    "        \"\"\"\n",
    "\n",
    "        response_text = call_openai(model=model, content=prompt)\n",
    "        print(response_text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d9ca46-6a4f-413d-9d99-e2c1792b476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # è°ƒç”¨gpt4o\n",
    "# for i, row in df.iterrows():\n",
    "#     qid = row[\"id\"]\n",
    "#     whole_question = row[\"whole_question\"]\n",
    "#     if qid == 21962:\n",
    "#         response_text = call_openai(prompt+whole_question)\n",
    "#         print(response_text)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22746556-0a42-4211-b821-e9047cce73c2",
   "metadata": {},
   "source": [
    "### æ‰¹é‡è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d32b7bf-3fb9-4226-a850-f4fa378e964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_call_openai(model):\n",
    "    # 1. è®¾ç½®æ•°æ®åº“è·¯å¾„ï¼ˆä½¿ç”¨ SQLite ç¤ºä¾‹ï¼Œä¹Ÿå¯æ›´æ¢ä¸º MySQL/PostgreSQLï¼‰\n",
    "    DATABASE_URL = \"sqlite:///gpt_response.db\"\n",
    "    \n",
    "    # 2. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    metadata = MetaData()\n",
    "    \n",
    "    # 3. å®šä¹‰è¡¨ç»“æ„ï¼ˆå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰\n",
    "    response_table = Table(\n",
    "        model.replace(\":\",\"-\"), metadata,\n",
    "        Column('id', String, primary_key=True),\n",
    "        Column('response', Text),\n",
    "    )\n",
    "    metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    \n",
    "    # 4. å¤„ç†æ¯ä¸€è¡Œæ•°æ®\n",
    "    # è¯»å– JSON æ–‡ä»¶ä¸º DataFrame\n",
    "    df = pd.read_json(\"CMedExamQA.json\")\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc='Processing'):\n",
    "        qid = row[\"id\"]\n",
    "        question = row[\"question\"]\n",
    "        opa = row[\"opa\"]\n",
    "        opb = row[\"opb\"]\n",
    "        opc = row[\"opc\"]\n",
    "        opd = row[\"opd\"]\n",
    "        ope = row[\"ope\"]\n",
    "\n",
    "        exists = session.query(response_table).filter_by(id=qid).first()\n",
    "        if exists:\n",
    "            # if i % 1000 == 0: print(f\"è·³è¿‡å·²å­˜åœ¨è®°å½•: {qid}\")\n",
    "            continue\n",
    "            \n",
    "        # è°ƒç”¨ollama\n",
    "        # prompt = f\"{question}\\nA. {opa}\\nB. {opb}\\nC. {opc}\\nD. {opd}\\nE. {ope}\"\n",
    "        prompt = f\"\"\"è¯·æ ¹æ®ä»¥ä¸‹åŒ»å­¦å•é€‰é¢˜ï¼Œä»äº”ä¸ªé€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åˆé€‚çš„ç­”æ¡ˆï¼Œå¹¶å°†ç­”æ¡ˆä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "        {{\"answer\": \"X\"}}\n",
    "        \n",
    "        å…¶ä¸­ X æ˜¯ Aã€Bã€Cã€D æˆ– E ä¸­çš„ä¸€ä¸ªé€‰é¡¹ã€‚è¯·ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–é¢å¤–ä¿¡æ¯ã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {question}\n",
    "        A. {opa}\n",
    "        B. {opb}\n",
    "        C. {opc}\n",
    "        D. {opd}\n",
    "        E. {ope}\n",
    "        \"\"\"\n",
    "\n",
    "        response_text = call_openai(model=model, content=prompt)\n",
    "        session.execute(response_table.insert().values(id=qid, response=response_text))\n",
    "\n",
    "        # æ¯100æ¡æäº¤ä¸€æ¬¡\n",
    "        if i % 100 == 0:\n",
    "            session.commit()\n",
    "            # print(f\"å·²æäº¤ {i} æ¡è®°å½•\")\n",
    "            \n",
    "    session.commit()  # âœ… åˆ«å¿˜äº† commit\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c7d2ed-461e-415e-ab37-2a601d39fa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b9de6161164a209128e37aa6616794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/10694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_call_openai(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e809cb7d-cf7b-4152-80ad-10b09441d382",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea619ffc-73a8-4dc3-885d-ae519e4e22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ æ•°æ®åº“ä¸­çš„è¡¨ï¼š\n",
      "['gpt-4o']\n",
      "âœ… è¡¨ `gpt-4o` ä¸­å…±æœ‰ 10694 æ¡è®°å½•\n",
      "\n",
      "ğŸ§± è¡¨ `gpt-4o` çš„å­—æ®µä¿¡æ¯ï¼š\n",
      "- id (VARCHAR)\n",
      "- response (TEXT)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "# è¿æ¥æ•°æ®åº“ï¼ˆä»¥ SQLite ä¸ºä¾‹ï¼‰\n",
    "DATABASE_URL = \"sqlite:///gpt_response.db\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# åˆ›å»º Inspector ç”¨äºåå°„\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# è·å–æ‰€æœ‰è¡¨å\n",
    "table_names = inspector.get_table_names()\n",
    "print(\"ğŸ“‹ æ•°æ®åº“ä¸­çš„è¡¨ï¼š\")\n",
    "print(table_names)\n",
    "\n",
    "# è·å–æ¯ä¸ªè¡¨çš„è¡Œæ•°\n",
    "with engine.connect() as conn:\n",
    "    for table in table_names:\n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM '{table}'\"))\n",
    "        count = result.scalar()\n",
    "        print(f\"âœ… è¡¨ `{table}` ä¸­å…±æœ‰ {count} æ¡è®°å½•\")\n",
    "\n",
    "for table in table_names:\n",
    "    print(f\"\\nğŸ§± è¡¨ `{table}` çš„å­—æ®µä¿¡æ¯ï¼š\")\n",
    "    columns = inspector.get_columns(table)\n",
    "    for col in columns:\n",
    "        print(f\"- {col['name']} ({col['type']})\")\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09beca99-7b9a-43ae-a827-e00e26d4b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ä¸€è¡Œæ•°æ®ï¼š ('413f38dc-3df2-5955-8858-16e460462f44', '{\"answer\": \"B\"}')\n",
      "ğŸ“¥ ID ä¸º a0a85ae8-48a3-5371-8e71-a60c600c0269 çš„ response:\n",
      "{\"answer\": \"E\"}\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "# è¿æ¥æ•°æ®åº“\n",
    "engine = create_engine(\"sqlite:///gpt_response.db\")\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# åå°„è·å–è¡¨\n",
    "response_table = metadata.tables[\"gpt-4o\"]\n",
    "\n",
    "# åˆ›å»ºè¿æ¥\n",
    "with engine.connect() as conn:\n",
    "    # 1ï¼‰æ‰“å°å‡ºä¸€è¡Œæ•°æ®\n",
    "    result = conn.execute(select(response_table).limit(1)).fetchone()\n",
    "    print(\"ğŸ“Œ ä¸€è¡Œæ•°æ®ï¼š\", result)\n",
    "\n",
    "    # 2ï¼‰æ ¹æ®ç‰¹å®š id æå– response\n",
    "    # target_id = 21962  # <-- æ›¿æ¢ä¸ºä½ çš„å®é™… ID\n",
    "    # target_id = 22616  # <-- æ›¿æ¢ä¸ºä½ çš„å®é™… ID\n",
    "    # target_id = \"413f38dc-3df2-5955-8858-16e460462f44\"\n",
    "    # target_id = \"45ba857a-8989-5527-89cc-d4320f8b3226\"\n",
    "    target_id = \"a0a85ae8-48a3-5371-8e71-a60c600c0269\"\n",
    "    # target_id = 23899  # <-- æ›¿æ¢ä¸ºä½ çš„å®é™… ID\n",
    "    stmt = select(response_table.c.response).where(response_table.c.id == target_id)\n",
    "    response = conn.execute(stmt).scalar()\n",
    "\n",
    "    if response:\n",
    "        print(f\"ğŸ“¥ ID ä¸º {target_id} çš„ response:\")\n",
    "        print(response)\n",
    "    else:\n",
    "        print(f\"âŒ æœªæ‰¾åˆ° ID ä¸º {target_id} çš„è®°å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3349a2-a53e-47d5-a45d-2fa6ce679564",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76846bf9-3f3d-4bbf-a285-8be222b099fa",
   "metadata": {},
   "source": [
    "## æå–æ•°æ®åº“ä¸­çš„responseï¼Œè§£æå‡ºç­”æ¡ˆï¼Œå¹¶ä¿å­˜ä¸ºtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c5453f-6613-4198-8a25-54822d62c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: A\n",
      "Example 2: C\n",
      "Example 3: D\n",
      "Example 4: B\n",
      "Example 5: NA\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_answer_from_response(response_str):\n",
    "    \"\"\"\n",
    "    ä»æ¨¡å‹å“åº”ä¸­æå– {\"answer\": \"X\"} æ ¼å¼çš„ç­”æ¡ˆã€‚\n",
    "    å¦‚æœæ— æ³•æå–æœ‰æ•ˆç­”æ¡ˆï¼Œåˆ™è¿”å› Noneã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON ç»“æ„\n",
    "        json_match = re.search(r'\\{.*?\\}', response_str, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group()\n",
    "            # å°è¯•è§£æä¸º JSON\n",
    "            parsed = json.loads(json_str)\n",
    "            if isinstance(parsed, dict) and 'answer' in parsed:\n",
    "                answer = parsed['answer'].strip().upper()\n",
    "                if answer in ['A', 'B', 'C', 'D', 'E']:\n",
    "                    return answer\n",
    "        return \"NA\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return \"NA\"\n",
    "\n",
    "# ç¤ºä¾‹å“åº”æµ‹è¯•\n",
    "example_responses = [\n",
    "    '{\"answer\": \"A\"}',\n",
    "    'Here is the answer:\\n{\"answer\": \"C\"}',\n",
    "    'ç­”ï¼š{\"answer\": \"D\"}ã€‚è¯·å‚è€ƒèµ„æ–™ã€‚',\n",
    "    'è§£é‡Šç•¥ã€‚\\n{\"answer\": \"B\"}\\nè°¢è°¢ï¼',\n",
    "    'é”™è¯¯æ ¼å¼',\n",
    "]\n",
    "\n",
    "for i, res in enumerate(example_responses, 1):\n",
    "    parsed = extract_answer_from_response(res)\n",
    "    print(f\"Example {i}: {parsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2137ff-7bbd-400e-ba82-da6ea3c46431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "\n",
    "# è¿æ¥æ•°æ®åº“\n",
    "engine = create_engine(\"sqlite:///gpt_response.db\")\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# åå°„è·å–è¡¨\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "\n",
    "llm_table = metadata.tables[model_name]\n",
    "\n",
    "id_response = []\n",
    "# åˆ›å»ºè¿æ¥\n",
    "i = 0\n",
    "file_name = \"gpt-4o\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    with open(f\"{file_name}.txt\", 'w') as f:\n",
    "        # æ ¹æ®ç‰¹å®š id æå– response\n",
    "        for target_id in df[\"id\"]:\n",
    "            stmt = select(llm_table.c.response).where(llm_table.c.id == target_id)\n",
    "            response = conn.execute(stmt).scalar()\n",
    "            \n",
    "            id_response.append({'id': target_id, 'response': response})\n",
    "            \n",
    "            answer = extract_answer_from_response(response)\n",
    "            if not answer:\n",
    "                print(target_id)\n",
    "                i += 1\n",
    "            if response:\n",
    "                f.write(target_id + \"\\t\" + answer + \"\\n\")\n",
    "            else:\n",
    "                print(f\"âŒ æœªæ‰¾åˆ° ID ä¸º {target_id} çš„è®°å½•\")\n",
    "\n",
    "with open(f\"{file_name}.json\", 'w') as json_file:\n",
    "    json.dump(id_response, json_file, indent=4)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae6203-e93f-4a12-bec9-b39ca0d9edab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
